# distributed

## 分布式事务


场景，1，订单和库存；2，服务调用超时；3，异步回调；4，分布式服务不可用；5，数据库与缓存；6，多级缓存；


两阶段提交协议，把分布式事务分成两个过程，准备阶段，协调者（事务管理器）向参与者（资源管理器）发起指令，参与者评估自己的状态，如果评估可以完成，则写redo和undo日志，然后锁定资源，执行操作，但并不提交。提交阶段，如果每个参与者明确返回准备成功，也就说预留资源和执行操作成功，协调者向参与者发起提交指令，参与者提交资源变更的事务，释放锁定的资源；如果任何一个参与者返回准备失败，也就说预留资源或执行操作失败，则协调者向所有参与者发起中止指令，每个参与者取消已经变更的事务，执行undo日志，释放锁定的资源。


两阶段提交的问题，1，阻塞，对任何一次指令必须收到明确的响应才会执行下一步，否则处于阻塞状态，占用的资源也一直被锁定；2，单点故障，若协调者宕机，参与者会一直阻塞，尽管可选举新的协调者，但如果之前的协调者在发送一个提交指令后宕机，而提交指令仅被一个参与者接收，并且参与者接收后也宕机，新的协调者将无法处理；3，协调者发送提交指令，有的接收到，提交事务，有的没有收到就没有提交，导致不一致；两阶段提交在正常情况下可保证强一致性，但在异常情况下，当前处理操作处于错误状态，需管理人员手工处理，可用性不好，也符合cap的c和a不可同时满足。


三阶段提交协议，是两阶段的改进版，通过超时机制解决了阻塞的问题，询问阶段，协调者询问参与者是否可完成指令，参与者只需要回答是或者不是，不需要真正的操作，这个阶段超时导致终止；准备阶段，如果在询问阶段所有参与者返回可以执行操作，协调者向参与者发送预执行请求，然后参与者写redo和undo日志，执行操作，但不执行，如果询问阶段任何参与者返回不能执行操作，则协调者向参与者发送中止请求，这个阶段超时导致成功；提交阶段，如每个参与者在准备阶段返回成功，协调者向每个参与者发提交指令，参与者提交资源变更的事务，释放锁定资源，如任何一个参与者返回准备失败，协调者向参与者发起中止指令，参与者取消已经变更的事务，执行undo日志，释放锁定资源。


相比二阶段，三阶段增加了一个询问阶段，可以确保尽可能早的发现无法执行操作而需要中止的行为，但并不能发现所有的这种行为，只会减少；准备阶段以后，协调者和参与者执行的任务中都增加了超时，一旦超时，协调者和参与者都继续提交事务，默认为成功，这也是根据概率统计上超时后默认成功的正确性最大，但一旦发生超时，系统仍然会发生不一致，只不过降低了发生的概率，好处是不会阻塞和永远锁定资源。


tcc协议，将一个任务拆分成try，confirm，cancel，正常流程先执行try，没有问题confirm，若出现问题cancel。从流程上讲，仍然是一个二阶段协议，不过有一定的自我修复能力，通过执行操作的逆操作达到最终一致状态。从逻辑上是简化的三阶段协议，解决了阻塞，但是没有解决极端情况下的不一致和脑裂问题。

参考：

- [seata设计原理](https://yq.aliyun.com/articles/715556?spm=a2c4e.11157919.spm-cont-list.23.3b31f2047Bulkr)


## 服务注册，zk，eureka，consul，nacos

cap理论，一致性c，所有的节点在同一时间具有相同的数据；可用性a，保证每个请求无论成功或失败都有响应；分区容忍，系统中任意信息的丢失或失败不影响系统的正常运行；a保证系统本身对外可用，而p则保证系统本事的正常运行。cap三者只能同时满足其中的两者，不能三者同时满足。

zk满足cp，不能保证a。对于数据存储的场景，一致性应该是首先被保证的，但对服务发现却不是，不同节点存储的服务提供信息不相同，也不会有太严重的后果。zk在进行leader选举的时候，服务是不可用的。

eureka则满足ap，不同于zk选举leader的过程，eu采用的p2p对等通信，是去中心化的架构，无master/slave之分，每个peer是对等的。节点通过彼此相互注册来提高可用性，每个节点需要添加一个或多个有效的serviceurl指向其他节点。每个节点都可被是为其他节点的副本。集群中如果某台server宕机，则client的请求会自动切换到新的server节点上，当宕机的server恢复后，eureka会再次将其纳入到服务器集群管理之中。当节点开始接收client请求时，所有的操作都会在节点间进行复制，将请求复制到该server当前所知的其他所有节点中。当一个新的server启动后，会首先尝试从邻近节点获取所有注册列表信息。并通过geteurekaserviceurls方法获取所有的节点，通过心跳契约定期更新。server在一定时间没有接收到某个服务实例的心跳（默认30秒）将会注销该实例（通过eureka.instance.lease-expiration-duration-in-seconds配置）。server节点端时间丢失过多心跳，将进入自我保护模式。eureka集群只要还有一台server还在，就能保证注册服务可用，虽然可能不是最新的。

eureka的另外一种自我保护机制，如果15分钟内超过85%的节点都没有正常心跳，那么eureka就认为client与注册中心出现了网络故障。eureka不再从注册表中移除因长时间没有收到心跳而过期的服务；eureka仍能够接收新服务注册和查询请求，但不会被同步到其他节点上；当网络稳定时，当前实例新注册的信息会被同步到其他节点中。


consul内置服务注册与发现，分布一致性协议实现，健康检查，kv存储，多数据中心方案等。遵循cp，保证强一致性和分区容错性，使用了raft算法。consul的强一致性导致服务注册比eureka慢，因为raft协议要求必须过半数的节点都写入成功才认为注册成功，leader挂掉时，重新选举期间整个consul不可用。相对，eureka则保证高可用和最终一致性。服务注册较快，因为不需要等注册信息replicate到其他节点，也不保证replicate成功。当数据不一致时，虽然a，b节点的注册信息不完全相同，但每个eureka仍然能够正常对外提供服务，但会出现查询服务信息时，请求a查询不到，但请求b就可以。


nacos是阿里开源，支持基于dns和基于rpc的服务发现。nacos除了服务的注册发现之外，还支持动态配置服务，可以让你以中心化，外部化和动态化的方式管理所有环境的应用配置和服务配置。动态配置消除了配置变更时重新部署应用和服务的需要。nacos=springcloud注册中心+springcloud配置中心。


参考：

- [jianshu](https://www.jianshu.com/p/bfcc8855f3d4)
- [nacos](https://nacos.io/zh-cn/docs/quick-start.html)




## 分布式锁




## 分布式缓存


## 唯一id
